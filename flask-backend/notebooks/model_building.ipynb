{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4396d6bc-b049-4243-a3a0-1b09a1f0d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e773a3a-6584-42e4-8b82-b215288c081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../artifacts/mbti_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "067d8b13-af76-4386-8f13-62ff3a8ea187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cff24f-5f34-4717-86bc-415ccba7218d",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e7a204f-cfa2-4cb4-8cad-5fa83aa62cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8675, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4140d5d-9b8e-464f-9ee7-eef6308624d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52f7ab91-1101-4cec-80fb-48ae54dd6d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type     0\n",
       "posts    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9478ebd8-dc00-479a-855d-8035b3c1a7dd",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89ee05e4-dbf1-4c32-9732-cd2a2188edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd95732-dc50-45ba-8ed5-613d99d9961b",
   "metadata": {},
   "source": [
    "Convert uppercase to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ae08c9b-49ac-409b-99ff-fc1f251f0ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"posts\"] = data[\"posts\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "data[\"type\"] = data[\"type\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "008ddcaf-5f51-4fa1-9465-dae467589237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    'http://www.youtube.com/watch?v=qsxhcwe3krw|||...\n",
       "1    'i'm finding the lack of me in these posts ver...\n",
       "2    'good one _____ https://www.youtube.com/watch?...\n",
       "3    'dear intp, i enjoyed our conversation the oth...\n",
       "4    'you're fired.|||that's another silly misconce...\n",
       "Name: posts, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"posts\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf24928f-3b01-44e6-ab23-199c42a9818a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    infj\n",
       "1    entp\n",
       "2    intp\n",
       "3    intj\n",
       "4    entj\n",
       "Name: type, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"type\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e767d4c1-5af4-4b78-acbd-782fc6e67f8c",
   "metadata": {},
   "source": [
    "Remove Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26ff9a72-0216-469d-878f-a2108549ff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"posts\"] = data['posts'].apply(lambda x: \" \".join(re.sub(r'https?://\\S+', '', x) for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30c57f80-67cc-46b0-8f46-2758f0ad772a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ' and intj moments sportscenter not top ten pl...\n",
       "1    'i'm finding the lack of me in these posts ver...\n",
       "2    'good one _____ course, to which i say i know;...\n",
       "3    'dear intp, i enjoyed our conversation the oth...\n",
       "4    'you're fired.|||that's another silly misconce...\n",
       "Name: posts, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"posts\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce188f50-d862-424a-99ca-29c0b0d8d134",
   "metadata": {},
   "source": [
    "Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8ac22a5-b6cd-4984-b6bc-9e7e04329c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b8a502e-046e-4bd4-9b3d-9cd7841a4884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text\n",
    "\n",
    "data[\"posts\"] = data[\"posts\"].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3eba8e5-c6fb-4f2e-a428-416b646e50db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     and intj moments sportscenter not top ten pla...\n",
       "1    im finding the lack of me in these posts very ...\n",
       "2    good one  course to which i say i know thats m...\n",
       "3    dear intp i enjoyed our conversation the other...\n",
       "4    youre firedthats another silly misconception t...\n",
       "Name: posts, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"posts\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc61117-e4ce-4acc-b88a-01f258a1676b",
   "metadata": {},
   "source": [
    "Remove numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b71d510c-3ba6-45bd-b290-950f48123545",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"posts\"] = data['posts'].str.replace('\\\\d+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5fafe39-39de-47b4-bf56-dd8c7a5e1eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     and intj moments sportscenter not top ten pla...\n",
       "1    im finding the lack of me in these posts very ...\n",
       "2    good one  course to which i say i know thats m...\n",
       "3    dear intp i enjoyed our conversation the other...\n",
       "4    youre firedthats another silly misconception t...\n",
       "Name: posts, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"posts\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f195bd-a095-4f5e-8576-a80be8978beb",
   "metadata": {},
   "source": [
    "Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "941a1e96-5aaf-46d5-aa56-fd674d370a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.4.16-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ------------------- -------------------- 20.5/42.0 kB ? eta -:--:--\n",
      "     -------------------------------------  41.0/42.0 kB 653.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 42.0/42.0 kB 503.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in d:\\projects\\previelyai\\flask-backend\\env\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: colorama in d:\\projects\\previelyai\\flask-backend\\env\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.5 MB 1.3 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.0/1.5 MB 653.6 kB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.1/1.5 MB 762.6 kB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.1/1.5 MB 656.4 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.5 MB 706.2 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.5 MB 696.3 kB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.5 MB 689.6 kB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.2/1.5 MB 654.9 kB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.3/1.5 MB 707.1 kB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.3/1.5 MB 679.4 kB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.3/1.5 MB 720.5 kB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.4/1.5 MB 675.0 kB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.4/1.5 MB 727.5 kB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.5/1.5 MB 704.5 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 0.5/1.5 MB 731.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 0.5/1.5 MB 713.7 kB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.6/1.5 MB 737.3 kB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.6/1.5 MB 743.1 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.6/1.5 MB 752.2 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.7/1.5 MB 770.0 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 0.7/1.5 MB 777.4 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 0.8/1.5 MB 768.0 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.8/1.5 MB 762.9 kB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.9/1.5 MB 788.4 kB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.9/1.5 MB 782.8 kB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.9/1.5 MB 795.1 kB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.5 MB 806.4 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 816.9 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.1/1.5 MB 826.7 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.2/1.5 MB 843.9 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.2/1.5 MB 852.1 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.3/1.5 MB 866.8 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 873.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.4/1.5 MB 893.6 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.4/1.5 MB 884.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 911.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 897.4 kB/s eta 0:00:00\n",
      "Downloading regex-2024.4.16-cp312-cp312-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.4 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 30.7/268.4 kB 1.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------ 61.4/268.4 kB 825.8 kB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 153.6/268.4 kB 1.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 184.3/268.4 kB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 256.0/268.4 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 268.4/268.4 kB 1.0 MB/s eta 0:00:00\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 61.4/97.9 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 97.9/97.9 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.2 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 30.7/301.2 kB 1.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 112.6/301.2 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 174.1/301.2 kB 1.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 266.2/301.2 kB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 301.2/301.2 kB 1.3 MB/s eta 0:00:00\n",
      "Installing collected packages: regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.4.0 nltk-3.8.1 regex-2024.4.16\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "274ee346-86c8-49bf-af91-f21e67e1e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed35cedf-5b2c-4b48-a6f0-350e39a0f653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to ../static/model...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords', download_dir='../static/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71cab6b2-73fc-4efb-9d52-3a514b276eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../static/model/corpora/stopwords/english', 'r') as file:\n",
    "    sw = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e12b8f9-a45b-4355-9373-cc8064734cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29b3c3c6-bc86-4a0a-a21a-fc624a0d1b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"posts\"] = data[\"posts\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75a262ab-6318-4514-bda3-5d6f9c24ec21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    intj moments sportscenter top ten plays pranks...\n",
       "1    im finding lack posts alarmingsex boring posit...\n",
       "2    good one course say know thats blessing cursed...\n",
       "3    dear intp enjoyed conversation day esoteric ga...\n",
       "4    youre firedthats another silly misconception a...\n",
       "Name: posts, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"posts\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ff04561-9d1e-4917-af97-09568276b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a70903d8-cc78-4822-9dfa-7d621913ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"posts\"] = data[\"posts\"].apply(lambda x: \" \".join(ps.stem(x) for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "707816eb-86f7-4e2b-8b36-9c2f71e3f044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    intj moment sportscent top ten play prankswhat...\n",
       "1    im find lack post alarmingsex bore posit often...\n",
       "2    good one cours say know that bless cursedo abs...\n",
       "3    dear intp enjoy convers day esoter gab natur u...\n",
       "4    your firedthat anoth silli misconcept approach...\n",
       "Name: posts, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"posts\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44e9b99-299b-4715-9ff0-462602568ca8",
   "metadata": {},
   "source": [
    "### Building Vacabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64aa15ec-2178-4d31-b0c6-5234f556c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "vocab1 = Counter()\n",
    "vocab2 = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41662f47-7d7e-46b1-9fce-f238c8aad65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in data['posts']:\n",
    "    vocab1.update(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ca8f85f-d642-4137-8017-8fedef9b67bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273519"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5397b8e-e9aa-4fe6-b18d-a5fca61228e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in data['type']:\n",
    "    vocab2.update(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc46f909-4011-4bf5-b223-5529be964d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1c5b8729-d982-4fb4-8c7f-9b4bec2e6ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'infp': 1832,\n",
       "         'infj': 1470,\n",
       "         'intp': 1304,\n",
       "         'intj': 1091,\n",
       "         'entp': 685,\n",
       "         'enfp': 675,\n",
       "         'istp': 337,\n",
       "         'isfp': 271,\n",
       "         'entj': 231,\n",
       "         'istj': 205,\n",
       "         'enfj': 190,\n",
       "         'isfj': 166,\n",
       "         'estp': 89,\n",
       "         'esfp': 48,\n",
       "         'esfj': 42,\n",
       "         'estj': 39})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "76ab24fc-dc61-4718-b1c6-0cefb305f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens1 = [key for key in vocab1 if vocab1[key] > 800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "097cb647-8cc2-4ea2-8acb-8eec3878ec86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1025"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e84d1242-d617-4f07-bf07-72f1fc3bb54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens2 = [key for key in vocab2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f4abd210-e516-48ee-bfec-449853ac7de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5a297816-49fa-4cf2-b3e7-dde98ae50c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vocabulary(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w', encoding=\"utf-8\")\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "\n",
    "save_vocabulary(tokens1, '../static/model/vocabulary1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "18fa2b9b-54d1-4df7-a384-c1c096a36a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vocabulary(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w', encoding=\"utf-8\")\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "\n",
    "save_vocabulary(tokens2, '../static/model/vocabulary2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a04dcc-ca91-4a17-9db8-ba370a47c455",
   "metadata": {},
   "source": [
    "### Divide dataset to train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c58c911a-afb6-49bc-a207-6704e82b9851",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[\"posts\"]\n",
    "y = data[\"type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7083fcc-7797-43b4-b72b-be9592a9d41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b611b4ee-0461-4445-b895-2ec6db19b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "39b200bf-758f-48c4-b2c9-cd3cc9027c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6940,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ca804697-40d2-436b-9d58-a3d1a4e61ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1735,)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1d4acaa4-f706-4148-b5b1-965b5fedf52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7894    that experi istp one know high threshold pass ...\n",
       "6394    like littl social energi anyon wish hold conve...\n",
       "1263    well consid convers friend month ago cost eat ...\n",
       "8004    still narrowmind misguid view absolut blow min...\n",
       "5655    im afraid share know anxiou hard sometim tell ...\n",
       "Name: posts, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "18ed55f7-456a-4fd7-9c75-c8ecf1e21953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7894    enfp\n",
       "6394    intp\n",
       "1263    intp\n",
       "8004    intp\n",
       "5655    infj\n",
       "Name: type, dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9f7d8f6f-9557-4e2d-99b8-aecd7a43c09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3117    isfp\n",
       "7900    infp\n",
       "1155    isfj\n",
       "6715    intp\n",
       "645     intj\n",
       "        ... \n",
       "4629    intp\n",
       "6104    intp\n",
       "7781    infp\n",
       "5502    infj\n",
       "7335    intj\n",
       "Name: type, Length: 1735, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6cd52b-4e8f-43b7-8676-d87e9c9f3763",
   "metadata": {},
   "source": [
    "### Vectoriztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "152bf76c-7964-4fa2-90f7-5022c70a376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(ds, vocabulary):\n",
    "    vectorized_lst = []\n",
    "    \n",
    "    for sentence in ds:\n",
    "        sentence_lst = np.zeros(len(vocabulary))\n",
    "        \n",
    "        for i in range(len(vocabulary)):\n",
    "            if vocabulary[i] in sentence.split():\n",
    "                sentence_lst[i] = 1\n",
    "                \n",
    "        vectorized_lst.append(sentence_lst)\n",
    "        \n",
    "    vectorized_lst_new = np.asarray(vectorized_lst, dtype=np.float32)\n",
    "    \n",
    "    return vectorized_lst_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "56ff53c4-1838-465c-a29b-152cf006c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_x_train = vectorizer(x_train, tokens1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d6dc3a8c-5f70-4ea4-8826-f23cfe27c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_x_test = vectorizer(x_test, tokens1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aaf0a0c7-d6bf-420d-9f6b-346ec8bd13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_y_train = vectorizer(y_train, tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0a24b9e9-805a-4727-a711-0d9e217330f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3c7c9763-e9b5-4a9e-a551-413d8a3f7b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_y_test = vectorizer(y_test, tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "66866498-5ccb-407c-a278-48de75a303e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "infp    1465\n",
       "infj    1167\n",
       "intp    1040\n",
       "intj     871\n",
       "entp     572\n",
       "enfp     537\n",
       "istp     273\n",
       "isfp     223\n",
       "entj     184\n",
       "istj     154\n",
       "enfj     144\n",
       "isfj     136\n",
       "estp      73\n",
       "esfp      37\n",
       "esfj      36\n",
       "estj      28\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168ac7ee-7e69-40b3-9575-f9dd2529552a",
   "metadata": {},
   "source": [
    "### handle imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9168ff37-8093-4301-9914-d80ac11208cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.12.2-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\projects\\previelyai\\flask-backend\\env\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in d:\\projects\\previelyai\\flask-backend\\env\\lib\\site-packages (from imbalanced-learn) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in d:\\projects\\previelyai\\flask-backend\\env\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\projects\\previelyai\\flask-backend\\env\\lib\\site-packages (from imbalanced-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\projects\\previelyai\\flask-backend\\env\\lib\\site-packages (from imbalanced-learn) (3.4.0)\n",
      "Downloading imbalanced_learn-0.12.2-py3-none-any.whl (257 kB)\n",
      "   ---------------------------------------- 0.0/258.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/258.0 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/258.0 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/258.0 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 30.7/258.0 kB 259.2 kB/s eta 0:00:01\n",
      "   ------ -------------------------------- 41.0/258.0 kB 245.8 kB/s eta 0:00:01\n",
      "   --------- ----------------------------- 61.4/258.0 kB 272.3 kB/s eta 0:00:01\n",
      "   ------------ -------------------------- 81.9/258.0 kB 305.0 kB/s eta 0:00:01\n",
      "   ------------ -------------------------- 81.9/258.0 kB 305.0 kB/s eta 0:00:01\n",
      "   ------------ -------------------------- 81.9/258.0 kB 305.0 kB/s eta 0:00:01\n",
      "   ------------ -------------------------- 81.9/258.0 kB 305.0 kB/s eta 0:00:01\n",
      "   ------------ -------------------------- 81.9/258.0 kB 305.0 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 122.9/258.0 kB 257.2 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 143.4/258.0 kB 283.8 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 163.8/258.0 kB 280.8 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 174.1/258.0 kB 275.8 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 174.1/258.0 kB 275.8 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 174.1/258.0 kB 275.8 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 194.6/258.0 kB 250.8 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 194.6/258.0 kB 250.8 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 204.8/258.0 kB 239.3 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 204.8/258.0 kB 239.3 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 204.8/258.0 kB 239.3 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 225.3/258.0 kB 229.3 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 225.3/258.0 kB 229.3 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 245.8/258.0 kB 228.2 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 245.8/258.0 kB 228.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- 258.0/258.0 kB 214.1 kB/s eta 0:00:00\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "52ea93ad-b7d4-44fe-8829-9027e654e565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23440, 1025) (23440, 16)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "vectorized_x_train_smote, vectorized_y_train_smote = smote.fit_resample(vectorized_x_train, vectorized_y_train)\n",
    "print(vectorized_x_train_smote.shape, vectorized_y_train_smote.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4baaf7-c723-4d42-bd3e-604d33ee5e55",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "223dae82-377f-442f-9e2c-1cd4cee6c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "842056fc-8153-4aa1-8620-721c530f506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def training_scores(y_act, y_pred):\n",
    "    acc = round(accuracy_score(y_act, y_pred), 3)\n",
    "    pr = round(precision_score(y_act, y_pred), 3)\n",
    "    rec = round(recall_score(y_act, y_pred), 3)\n",
    "    f1 = round(f1_score(y_act, y_pred), 3)\n",
    "    print(f'Training Scores:\\n\\tAccuracy = {acc}\\n\\tPrecision = {pr}\\n\\tRecall = {rec}\\n\\tF1-Score = {f1}')\n",
    "    \n",
    "def validation_scores(y_act, y_pred):\n",
    "    acc = round(accuracy_score(y_act, y_pred), 3)\n",
    "    pr = round(precision_score(y_act, y_pred), 3)\n",
    "    rec = round(recall_score(y_act, y_pred), 3)\n",
    "    f1 = round(f1_score(y_act, y_pred), 3)\n",
    "    print(f'Testing Scores:\\n\\tAccuracy = {acc}\\n\\tPrecision = {pr}\\n\\tRecall = {rec}\\n\\tF1-Score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd16ded-b57e-4f79-aed8-aaa975fa9da0",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b996fb9-45ab-4cf6-bca6-1371c3f17249",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[43mLogisticRegression\u001b[49m()\n\u001b[0;32m      3\u001b[0m vectorized_y_train_smote_1d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(vectorized_y_train_smote, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m vectorized_y_train_1d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(vectorized_y_train, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "vectorized_y_train_smote_1d = np.argmax(vectorized_y_train_smote, axis=1)\n",
    "vectorized_y_train_1d = np.argmax(vectorized_y_train, axis=1)\n",
    "lr.fit(vectorized_x_train_smote, vectorized_y_train_smote_1d)\n",
    "\n",
    "y_train_pred = lr.predict(vectorized_x_train_smote)\n",
    "\n",
    "y_test_pred = lr.predict(vectorized_x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d8f82ba-7ab4-4b10-acf9-577f11894e40",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43my_test_pred\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test_pred' is not defined"
     ]
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "30724ef3-c7ea-4cd0-bd86-2bf9988aeca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_y_test_1d = vectorized_y_train_1d = np.argmax(vectorized_y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9b1b16-e10e-4846-bb03-e9d6f95345b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
